{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c1a014-6b6b-4db2-af77-75e9f4a6a232",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:1px;color:DarkSlateBlue; background-color:DarkSlateBlue;border:none; height:4px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82677da-5618-428a-a814-1b4e08a02c58",
   "metadata": {},
   "source": [
    "\n",
    "<h5 style=\"font-size:20; color:#191970;font-family:monospace\"><u>Brief Description:</u></h5>\n",
    "<p style=\"font-size:18; color:#191970;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "Analyzing WhatsApp chat data can provide valuable insights beyond sentiment analysis. Here are some additional ways in which WhatsApp chat analysis can be important:\n",
    " <ul style=\"color: #191970;font-family:monospace\"><li>Content understanding,</li>\n",
    "    <li>User activity,</li>\n",
    "    <li>Participant engagement,</li>\n",
    "    <li>Social Network,</li>\n",
    "    <li>Content and Link sharing,</li> \n",
    "    <li>User Behaviour pattern etc.</li></ul></p>\n",
    "<p style=\"font-size:18; font-weight:600;color:#191970;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "WhatsApp chat analysis involves studying chat data to gain insights into topics, user behavior, content sharing, engagement, and communication patterns. It offers valuable information for understanding conversations, optimizing communication strategies, monitoring user activity, and more, without focusing on sentiment analysis.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b6e141-59c7-46fd-968e-35843198f088",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:1px;color:DarkSlateBlue; background-color:DarkSlateBlue;border:none; height:4px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a6cfa-2a91-4e9b-86d9-7d59a0d5798e",
   "metadata": {},
   "source": [
    "<h5 style=\"font-size:20; color:#191970;font-family:monospace\"><u>Methodology (in swift):</u></h5>\n",
    "\n",
    "<ol style=\"font-size:18; color:#191970; text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <li><b>Importing Libraries</b>: Various libraries like re, nltk, pandas, numpy, emoji, collections, and matplotlib.pyplot` are imported.</li>\n",
    "\n",
    "<li><b>Loading Chat Data</b>: The WhatsApp Chat data is loaded from a text file.</li>\n",
    "\n",
    "<li><b>Dataprocessing</b>: Text data is preprocessed and cleaned for further analysis. This involves date & time extraction, emoji extraction, word frequency count, and so on.</li>\n",
    "\n",
    "<li><b>Creating DataFrame</b>: A pandas DataFrame is created store the processed chat data.</li>\n",
    "\n",
    "<li><b>Information Extraction</b>: Important features are extracted from the data such as top users, daily timeline, monthly, busiest day and month, and so on.</li>\n",
    "\n",
    "<li><b>Data Description</b>: Descriptive statistics is computed on the data.</li>\n",
    "\n",
    "<li><b>Plotting Graphs</b>: Graphs and charts like heatmaps and word clouds are generated to visualize the chat data and draw meaningful insights.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee010dc-0d58-4d71-88af-3a31da446e4c",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:1px;color:DarkSlateBlue; background-color:DarkSlateBlue;border:none; height:4px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1121a855-0502-4200-9871-22452cd2cc61",
   "metadata": {},
   "source": [
    "<p style=\"font-size:28;font-weight:600; color:#191970;text-align:justify;text-justify: initial;font-family:monospace\"><font size=\"4\">\n",
    "    As a student embarking on this project, I've just completed the initial project setup, including importing necessary libraries and loading the WhatsApp chat data. The next steps will involve processing the data, creating a DataFrame, extracting key information, and ultimately visualizing the output through code to gain valuable insights from the chat data.\n",
    "</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cead76b-66e9-46f8-9ab8-e26d4236f8d0",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:1px;color:DarkSlateBlue; background-color:DarkSlateBlue;border:none; height:4px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18fd12-e7b1-4d0b-a5e8-1e7ba7a102bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import collections\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import hvplot.pandas\n",
    "import simple_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_ = r\"WhatsAppGroupChat.txt\" #put your file name here, process of exporting is stated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e42c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Exist or not checker\n",
    "import os\n",
    "\n",
    "def check_file_existence(file_path_):\n",
    "    if os.path.exists(file_path_):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    if check_file_existence(file_path_):\n",
    "        print(f\"The file '{file_path_}' exists.\")\n",
    "    else:\n",
    "        print(f\"The file '{file_path_}' does not exist.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6854fec-4b64-4074-8b59-d3f96a5278d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Date and Time\n",
    "def date_time(s):\n",
    "    pattern = r'^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)([ ]|.)?(AM|PM|am|pm)? -'\n",
    "    result = re.match(pattern, s)\n",
    "    if result:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Extract Messenger ================================================\n",
    "def messenger(s):\n",
    "    s = s.split(\":\")\n",
    "    if len(s) == 2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Extract Messages ================================================\n",
    "def message_data(line):\n",
    "    splitline = line.split(' - ')\n",
    "    dateTime = splitline[0]\n",
    "    date, time = dateTime.split(\", \")\n",
    "    message = \" \".join(splitline[1:])\n",
    "    if messenger(message):\n",
    "        splitmessage = message.split(\": \")\n",
    "        author = splitmessage[0]\n",
    "        message = \" \".join(splitmessage[1:])\n",
    "    else:\n",
    "        author = None\n",
    "    return date, time, author, message\n",
    "\n",
    "# Dummy tuple =================================================\n",
    "data = []\n",
    "\n",
    "# Main block =================================================\n",
    "try:\n",
    "    with open(file_path_, encoding=\"utf-8\") as fp:\n",
    "        fp.readline()  # Skip the header line if any\n",
    "        messageBuffer = []\n",
    "        date, time, author = None, None, None\n",
    "        while True:\n",
    "            line = fp.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if date_time(line):\n",
    "                if len(messageBuffer) > 0:\n",
    "                    data.append([date, time, author, ' '.join(messageBuffer)])\n",
    "                messageBuffer.clear()\n",
    "                date, time, author, message = message_data(line)\n",
    "                messageBuffer.append(message)\n",
    "            else:\n",
    "                messageBuffer.append(line)\n",
    "\n",
    "except Exception as e:  # Improved error handling\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # Handle the error accordingly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188ea70-2f85-427b-a71b-4f89772ee426",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The <u>preprocessing Python script</u> <i>defines functions to extract date and time, detect messenger format, and parse message data</i> from a text file. It then processes the file, handling errors with improved exception handling. The <i>extracted data is stored in a list of lists, and a Pandas DataFrame is created to organize it with columns for Date, Time, Author, and Message</i>. This DataFrame facilitates further analysis and manipulation of the message data. Overall, <u>the code now includes error handling, employs a clearer structure, and enhances data organization</u> for better utilization in data analysis tasks using Pandas.</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db64ef09-5fd4-4612-a3f2-a7e973d15acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "u='\\033[4m'\n",
    "r='\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89797d-dcd5-4012-acf2-35613aa5318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "df = pd.DataFrame(data, columns=['Date', 'Time', 'Author', 'Message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad97fa1-db52-4715-8566-4faf73eedfba",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px; font-weight:400; color:Brown;text-decoration:overline underline;font-family:monospace\">Pre-processing steps: Date, Time, Author_Name(sender) and Messsage extracted, Dataframe created.</p>\n",
    "<h4 style=\"font-size:18px; font-weight:400; color:#00008B;font-family:monospace\"><u>Current dataframe structure</u>:</h4><p style=\"font-size:16px; font-weight:300; color:#00008B;font-family:monospace\">(Column_Name Non_Null_Count Data_Type)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7bb06b-356e-4c6a-8756-8e0275840ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35b628-2426-4ade-a359-d8fe374526cd",
   "metadata": {},
   "source": [
    "<h4 style=\"font-size:24px; font-weight:500; color:#00008B;font-family:monospace\"><u>Data_Cleaning Processes</u>:</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea58ca-3e96-4339-a9aa-902f158db662",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:500; color:#00008B;font-family:monospace\">\n",
    "        <li><u>Checking and removing NaN/NULL values.</u></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e65774-2c81-418e-89b3-e93ba9e412a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking no. of null values in dataset\n",
    "print(f'{u}Checking no. of null values in dataset:{r}')\n",
    "print(df.isnull().sum())\n",
    "#removing null--------------------------------------------------------\n",
    "df=df.dropna()\n",
    "print( f'{u}Checking no. of null values in dataset:{r}')\n",
    "print(df.isnull().sum())\n",
    "print( simple_colors.red('Null values deleted succesfully.', ['bold', 'underlined','italic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4594ff-e10f-4634-8847-de9f5aa91b1b",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">We started by checking the <u>null values in the dataset</u> using the code snippet. First, we printed the number of null values for each column. Then, we removed the rows with null values from the DataFrame. After that, we checked again to confirm that there were no more null values. Finally, we added a print statement in red to signify the successful deletion of null values. The <i>entire process ensures a clean dataset without any missing values, ready for further analysis.</i></i>.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d015d8-4200-4e44-95e7-fb15b323c451",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:500; color:#00008B;font-family:monospace\">\n",
    "        <li>Changing sender names for privacy:</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97f90b-8b7c-48eb-8410-6a88f453790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hiding the Names/Numbers of sender (Privacy)=======\n",
    "Temp_auth_list=df['Author'].unique().tolist()\n",
    "num_elements =1000\n",
    "sender_list = [f'Sender {i}' for i in range(1, num_elements + 1)]\n",
    "author_dict= dict(zip(Temp_auth_list,sender_list ))\n",
    "\n",
    "print(f'{u}New title for Sender/Author:{r}')\n",
    "df['Author'] = df['Author'].replace(author_dict)\n",
    "print(df['Author'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d59ef8-8281-40f9-8fe2-8963fdbc02da",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">A <u>privacy-focused</u> approach has been implemented in the code to <i>hide sender names or numbers</i>. The unique authors from the DataFrame are <i>assigned temporary labels, such as 'Sender 1', 'Sender 2', and so on</i>. The original sender names or numbers are replaced with these anonymized labels. This <i>ensures confidentiality by masking the actual identities. The code successfully transforms the 'Author' column, providing a layer of privacy protection while maintaining data integrity</i>.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40582c61-29d8-447d-8f4d-74e481f84643",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Removing stopwords, punctuations and group notifications.</li>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c8ded-d9fc-4bf1-919b-18c008f2c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(message):\n",
    "  f = open('stop_hinglish.txt', 'r', encoding='utf-8')\n",
    "  stop_words = f.read()\n",
    "  y = []\n",
    "  for word in message.lower().split():\n",
    "      if word not in stop_words:\n",
    "          y.append(word)\n",
    "  return \" \".join(y)\n",
    "\n",
    "df['Message'] = df['Message'].apply(remove_stop_words) #remove stopwords\n",
    "print( simple_colors.red('Stopwords removed.', ['bold', 'underlined','italic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a318192-6fd5-4a81-850a-abe43d4a0c78",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code defines a <i>function remove_stop_words to eliminate stopwords from a DataFrame column ('Message') using a predefined list from a file. The function converts text to lowercase, removes stopwords, and updates the DataFrame. The print statement uses simple_colors to indicate that stopwords have been successfully removed, applying formatting like bold, underlined, and italic for emphasis.</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df997a6e-c271-4d67-9515-848f1c89a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(message):\n",
    "  x = re.sub('[%s]'% re.escape(string.punctuation), '', message)\n",
    "  return x\n",
    "\n",
    "df['Message'] = df['Message'].apply(remove_punctuation) #remove punctuations\n",
    "print( simple_colors.red('Punctuations removed.', ['bold', 'underlined','italic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d6935b-ecc5-44d9-85a5-e527bc175807",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code <i>defines a function remove_punctuation to remove punctuation from messages in a DataFrame using regular expressions</i>. It applies this function to the 'Message' column, effectively <i>eliminating punctuation marks</i>. A <u>confirmation message is printed</u> using the simple_colors library, indicating the successful removal of punctuations from the messages in the DataFrame.</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f4c336-e9cf-42af-b00c-e0e8a97ac807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data\n",
    "df = df[df['Message'] != 'This message was deleted']\n",
    "\n",
    "df = df[df['Message'] != 'null']\n",
    "\n",
    "df = df[df['Message'] != 'message deleted']\n",
    "\n",
    "df = df[df['Message'] != 'deleted message']\n",
    "\n",
    "df = df[df['Message'] != 'missed voice call']\n",
    "\n",
    "df = df[df['Message'] != 'missed video call']\n",
    "\n",
    "print( simple_colors.red('Printing dataframe:', ['bold', 'underlined','italic']))\n",
    "\n",
    "df = df[df['Message'].str.strip() != '']\n",
    "# Print the cleaned DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeee683-7fad-41e1-868f-bd9e9952c0ca",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">In the data cleaning process, the code <i>removes rows with specific message content such as deleted messages, null values, missed voice calls, and missed video calls</i>. Additionally, <i>it eliminates rows with whitespace-only messages</i>. The <u>resulting cleaned DataFrame</u>, excluding the specified messages, is then printed with formatting, emphasizing the data cleaning steps.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa0cd4",
   "metadata": {},
   "source": [
    "<h4 style=\"font-size:18px; font-weight:600; color:red;font-family:monospace\"><u>Data preliminary cleaning process completed.</u></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36313a3-eb07-479b-9c0e-013bc7f72490",
   "metadata": {},
   "source": [
    "<h4 style=\"font-size:22px; font-weight:400; color:#00008B;font-family:monospace\"><u>Dataframe Overhauling Processes:</u></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6c44e1-557b-4966-be31-24a1a08f349e",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Modifying date and time column.</li>  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a6732c-f206-4908-800a-eadd27cfc9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restructuring date and time column\n",
    "print( simple_colors.red('Primary columns of the Dataframe:', ['bold', 'underlined','italic']))\n",
    "print(df.columns)\n",
    "df[\"Date&Time\"]=df['Date']+' '+df['Time']\n",
    "df= df.drop('Time', axis=1)\n",
    "df= df.drop('Date', axis=1)\n",
    "df=df[['Date&Time','Author','Message']]\n",
    "print( simple_colors.red('Revised columns of the Dataframe:', ['bold', 'underlined','italic']))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0235e-383f-4688-b8b5-0b4cca6dae8a",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">\n",
    "The code<u> restructures a DataFrame by combining 'Date' and 'Time' columns into a new 'Date&Time' colum</u>n. The<i> original 'Time' and 'Date' columns are then dropped, and the DataFrame is rearranged to have 'Date&Time,' 'Author,' and 'Message' as the primary column</i>s. The revised columns are displayed for confirmation.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034765a-79c2-4e5d-8dd7-04173d10d2f7",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Reshaping Date&Time column datatype:</li>  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd9479-c2cc-4908-a66d-ff25c61b037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the DateTime column to datetime format\n",
    "print(f\"{u}Before Formatting:{r}\\n\")\n",
    "print(df['Date&Time'].head(5),\"{r}\\n\")\n",
    "df['Date&Time'] = pd.to_datetime(df['Date&Time'])\n",
    "print(f\"{u}After Formatting:{r}\\n\")\n",
    "print(df['Date&Time'].head(5))\n",
    "print(simple_colors.red('As the Date&Time was in raw text format we now changed it to Date_Time format as YYYY-MM-DD HH:MM:SS.',['bold', 'underlined','italic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a609ab-f1a7-43ae-994d-9620a62efa38",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">\n",
    "The code converts the<u> 'Date&Time' column in a DataFrame to datetime format using Pandas' pd.to_datetime functio</u>n. It then displays the original and formatted date and time values, emphasizing the conversion from raw text to the standard<i> YYYY-MM-DD HH:MM:S</i>S format in a bold, underlined, and italicized red message</font></p>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73a4a28-7aa5-4c38-9956-98d320d98a95",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Adding additional columns to get helpful insights during extraction.</li>  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9192b1-cf25-40c6-8645-c0468660ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting date&time column ====================================\n",
    "df['Only_date'] = df['Date&Time'].dt.date\n",
    "df['Year'] = df['Date&Time'].dt.year\n",
    "df['Month_No'] = df['Date&Time'].dt.month\n",
    "df['Month'] = df['Date&Time'].dt.month_name()\n",
    "df['Day'] = df['Date&Time'].dt.day\n",
    "df['Day_name'] = df['Date&Time'].dt.day_name()\n",
    "df['Hour'] = df['Date&Time'].dt.hour\n",
    "df['Minute'] = df['Date&Time'].dt.minute\n",
    "print(simple_colors.red(\"After splitting 'Date&Time' column, revised columns are as follows:\", ['bold', 'underlined','italic']))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243137d8-513d-4fac-a051-fbf4849581f9",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code <i>splits the 'Date&Time' column in a DataFrame into separate columns for date, year, month number, month name, day, day name, hour, and minute</i>i>. The <u>resulting columns provide a detailed breakdown of temporal information</u>. The revised columns are displayed using a formatted print statement.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c6402-678e-4c72-9969-7f900058c048",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Adding Hour_to_Hour period to get help in further steps during extraction.</li>  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed592104-4578-4f5e-bba4-bfc59019c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hour to Hour collection =======================================\n",
    "period = []\n",
    "for hour in df[['Day_name', 'Hour']]['Hour']:\n",
    "    if hour == 23:\n",
    "        period.append(str(hour) + \"-\" + str('00'))\n",
    "    elif hour == 0:\n",
    "        period.append(str('00') + \"-\" + str(hour + 1))\n",
    "    else:\n",
    "        period.append(str(hour) + \"-\" + str(hour + 1))\n",
    "\n",
    "df['Hour_Period'] = period\n",
    "print(simple_colors.red(\"After adding 'Hour_Period' column, revised columns are as follows:\", ['bold', 'underlined','italic']))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42734918-2015-4ca8-a25f-4856174d6e5d",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">A new column <i>'Hour_Period' is created in a DataFrame</i>, representing time periods based on the 'Hour' column. The periods range from one hour to the next, handling the transition from 23 to 00. The <u>revised DataFrame includes this additional column for improved time-based analysis</u>.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085685cd",
   "metadata": {},
   "source": [
    "<h4 style=\"font-size:22px; font-weight:400; color:#00008B;font-family:monospace\"><u>Extraction of useful insights:</u></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3c7c4",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Checking valuable insights of the dataframe.</li>  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f370ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515eee8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "<h5 style=\"font-size:20; color:#191970;font-family:monospace\"><u>Overview of the above description:</u></h5>\n",
    "<p style=\"font-size:18; color:#191970;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "The df.describe() function in pandas is like a summary report for your data. It gives you a quick overview of the main statistics for each column (or feature) in your DataFrame. Here's what it tells you:\n",
    " <ol style=\"color: #191970;font-family:monospace\">\n",
    "     <li><b>Count</b>: The number of non-missing (non-null) values in each column. This tells you how many data points you have for each feature.</li>\n",
    "     <li><b>Mean</b>: The average value for each feature. It's the sum of all values divided by the count. This gives you an idea of the central tendency of your data.</li>\n",
    "     <li><b>Standard Deviation (std)</b>: This measures the amount of variation or dispersion in your data. A higher standard deviation means that the data points are more spread out from the mean.</li>\n",
    "     <li><b>Minimum (min)</b>: The smallest value in each column, showing the minimum value observed.</li> \n",
    "     <li><b>25th Percentile (25%)</b>: This is the value below which 25% of your data falls. It gives you an idea of the lower end of your data distribution.</li>\n",
    "     <li><b>50th Percentile (50%)</b>: Also known as the median, this is the value below which 50% of your data falls. It's a good measure of the central point of your data distribution.</li>\n",
    "     <li><b>75th Percentile (75%)</b>: This is the value below which 75% of your data falls. It gives you an idea of the upper end of your data distribution.</li>\n",
    "     <li><b>Maximum (max)</b>: The largest value in each column, showing the maximum value observed.</li>\n",
    "</ol></p>\n",
    "<p style=\"font-size:18; font-weight:600;color:#191970;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "By running df.describe(), we can quickly get a sense of the data's distribution, identify potential outliers, and understand the basic statistics of each feature in your DataFrame. It's a helpful starting point for data exploration and analysis in pandas.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c48aae",
   "metadata": {},
   "source": [
    "<h5 style=\"font-size:20; color:#191970;font-family:monospace\"><u>Insights from the above description:</u></h5>\n",
    "<ol style=\"color: #191970;font-family:monospace\">\n",
    "    <li>The <b>first message</b> sent was on: 2020-04-17 19:20:00</li>\n",
    "    <li>The  <b>last message</b> sent was on:  2023-09-06 03:48:00</li>\n",
    "    <li><b>25% of the chats</b> was on/before:2020-12-27 23:33:00</li>\n",
    "    <li><b>50% of the chats</b> was on/before:2021-03-05 23:40:00</li>\n",
    "    <li><b>75% of the chats</b> was on/before:2021-11-25 12:19:00</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab72d79-3a5b-4e8f-98e0-87b4b4588cd3",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Top sender(s) of the coversation:</li>  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99532d65-9d0f-457b-b2a5-b63f6e99358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df['Author'].value_counts().head(5)\n",
    "print(f\"{u}Top sender(s) and their message count:{r}\\n\")\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d1caed-b0ed-4132-8a24-f7cd0b130303",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code <i>calculates the top 5 senders and their respective message counts from the 'Author' column in a DataFrame</i>. The <u>results are printed in a formatted message, indicating the most active contributors and their corresponding message counts</u>.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9074733a-c4d0-46db-b745-c358ce473e22",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Sender and their messege percentage in the conversation:</li>  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096e041-2e8f-4a77-8164-1e5c03609451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Percentage users & their messages =============================\n",
    "new_df = round(((df['Author'].value_counts() / df.shape[0]) * 100), 2).reset_index()\n",
    "new_df=new_df.rename(columns={'Author': 'Code_Name', 'count': 'Percent'})\n",
    "print(f\"{u}Involvement of each sender by percentage of message sent:{r}\\n\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d7d383-8ad0-4ec7-a3df-a7ea59c0a715",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code <u>calculates the percentage of messages sent by each user in a DataFrame</u>. It uses the 'Author' column to determine the message count for each user, rounds the percentages to two decimal places, and prints the results. The <i>'Code_Name' and 'Percent' columns are renamed for clarity.</i></u></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe08693-8666-4fbb-a3cf-83d61aeb546c",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Total number of words in the conversation:</li>  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d5d35b-c0f7-4525-b1f6-30d5fa706daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Number of words ========================================\n",
    "words = []\n",
    "for message in df['Message']:\n",
    "  words.extend(message.split())\n",
    "print(f\"{u}Total number of words present in message:{r}\",len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93471f29-98b3-4b1a-a229-f0936d88f327",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">\n",
    "The code counts the<i> total number of words in the 'Message' column of a DataFram</i>e. It iterates through each message, splits them into words, and appends them to a list. The<u> total word count is then printed.</u></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f40cbdd-7734-4c0d-a972-be6924697ee6",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Total number of media sent in the conversation:</li>  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c500f-df4a-49a4-a113-624eae6be427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting Media sent in the group ===============================\n",
    "#dup_df=df[['Author','Message']].copy()\n",
    "df['Word_Count']=df['Message'].str.count('media omitted')\n",
    "WordCount=(df['Word_Count']==1).sum()\n",
    "print(f\"{u}Number of Media  present in coversation{r}:\",WordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0d401-bd47-4297-ac66-b9a7d08cfcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{u}Dropped all the rows with message 'Media Omitted'{r}:\",WordCount)\n",
    "#Dropping Rows with Media Omitted Values\n",
    "df=df[df.Word_Count != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4195a1-88c9-4359-8c23-cbb0e8f0c01c",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code <i>counts the occurrences of the phrase 'media omitted' in the 'Message' column of a DataFrame and prints the number of times it appears<i>. It then <u>drops the rows containing this phrase, updating the DataFrame accordingly.</u></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64669e4e-2a2e-4b0c-bb40-242ea67d4711",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Total number of links sent in the conversation:</li>  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd8fb12-d070-4cf1-9b2f-acfec8e5647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Links Shared ========================================\n",
    "from urlextract import URLExtract\n",
    "extract = URLExtract()\n",
    "\n",
    "links = []\n",
    "for message in df['Message']:\n",
    "    links.extend(extract.find_urls(message))\n",
    "print(f\"{u}Total number of links present in message:{r}\\n\")\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d1917-4bf6-44ce-a256-9f0fc31c8e5e",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code utilizes the <u>'urlextract' library to extract URLs from messages in a DataFrame</u>. It iterates through the 'Message' column, finds and stores URLs using the URLExtract class. The <i>total number of links is then printed. The result provides insights into the quantity of shared links.</i></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d69dc-d4c5-41e5-9e39-797ed66ff16f",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Emoji analysis in the conversation:</li>  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bf86b-6ead-4b02-ba18-3a21f46dcdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emojis in the chat =============================================\n",
    "emojis = []\n",
    "for message in df['Message']:\n",
    "    emojis.extend([c for c in message if c in emoji.EMOJI_DATA])\n",
    "    pd.DataFrame(Counter(emojis).most_common(len(Counter(emojis))))\n",
    "#print(emojis)\n",
    "\n",
    "\n",
    "#grouping emojis ================================================\n",
    "emoji_count={}\n",
    "for e in emojis:\n",
    "    if e in emoji_count:\n",
    "        emoji_count[e]+=1\n",
    "    else:\n",
    "        emoji_count[e]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f0231-1167-4ba8-99a1-3b20b55eff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting dict by values (desc) ==================================\n",
    "emoji_count=dict(sorted(emoji_count.items(), key=lambda item: item[1], reverse=True))\n",
    "print(f\"{u}Top 10 emojis used in message:{r}\\n\")\n",
    "print(dict(list(emoji_count.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72892eca-a480-40b1-84b4-d3593de0c603",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code <i>extracts emojis from chat messages, counts their occurrences, and creates a sorted dictionary based on frequency</i>. The <u>result displays the top emojis used in messages</u>. Emojis are collected and counted, providing insights into the most frequently used symbols in the chat data.</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ad07b-7f32-4a03-8c1a-af7e483019bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Emoji_Count'] = df['Message'].str.count(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U0001FAB0-\\U0001FABF\\U0001FAC0-\\U0001FAFF\\U0001FAD0-\\U0001FAFF\\U0001FAE0-\\U0001FAFF\\U0001FAF0-\\U0001FAFF\\U0001F4AA]')\n",
    "\n",
    "# Calculate the total number of emojis sent by each user\n",
    "emoji_counts = df.groupby('Author')['Emoji_Count'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Find the user with the highest emoji count\n",
    "user_with_most_emojis = emoji_counts[:10]\n",
    "\n",
    "print(f\"{u}The user who sent the most emojis are:\\n{r}{user_with_most_emojis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bf2769-e8e2-4497-9a3a-f06dc31c952a",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code <i>calculates the total number of emojis sent by each user in a DataFrame</i>. It creates a new column 'Emoji_Count', groups the data by the 'Author,' and computes the sum of emoji counts. The <u>result is a list of users ranked by the highest emoji count</u>, displayed for the top users.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937936de-8a56-4568-91dc-bed6fa140699",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Percentage of (generic) abusive words used in converstaion:</li>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008ddae-0d51-4176-a489-c8986e4b5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read target words from a text file\n",
    "with open('abusive.txt', 'r') as file:\n",
    "    target_words = [line.strip() for line in file]\n",
    "\n",
    "# Use str.contains() with logical OR to check if any of the words are present in each row\n",
    "# Then use sum() to count the occurrences\n",
    "word_count = df['Message'].str.contains('|'.join(target_words)).sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"{u}The abusive (target) words appear {word_count} times in the 'Message' column.{r}\")\n",
    "total_words = df['Message'].apply(lambda x: len(x.split())).sum()\n",
    "percentage_abusive_words = (word_count / total_words) * 100\n",
    "print(f\"{u}The percentage of abusive words compared to total words is: {percentage_abusive_words:.2f}%.{r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b630884-215a-4c00-87d1-d9641c8c0b0f",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code <i>reads a list of <u>abusive words</u> from a file, checks their occurrences in the 'Message' column of a DataFrame using logical OR, and counts them</i>. The result is printed, indicating the number of times abusive words appear in the messages.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da30502-2ca5-4f05-a443-dc5132a29bed",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Word frequency of the conversation:</li>  \n",
    "</ul>\n",
    "<p style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">(Removed stopwords, other target words, emoji(s) and group notifications.)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea2d4b2-9215-4594-be4c-613761c5e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U0001FAB0-\\U0001FABF\\U0001FAC0-\\U0001FAFF\\U0001FAD0-\\U0001FAFF\\U0001FAE0-\\U0001FAFF\\U0001FAF0-\\U0001FAFF\\U0001F4AA]'\n",
    "\n",
    "# Remove emojis from the 'Text' column\n",
    "df['Message'] = df['Message'].str.replace(emoji_pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d882a64-9cbc-4601-959c-ce5cd2c27acd",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Word frequency (most frequent wors):</li>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548085a-c847-4e58-952a-02568df68988",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq=collections.Counter(df[\"Message\"])\n",
    "print(f\"{u}Word_Frequency (Most Common 20):{r}\\n\")\n",
    "word_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcead980-2950-4ce8-97c5-6ed666f166b2",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code uses the <i>'collections.Counter'</i> to <u>calculate the word frequency in the 'Message' column of a DataFrame</u>. It then prints the most common 20 words and their counts. This provides insights into the frequently used words in the dataset.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3016d694-dcb6-4339-923a-fe2c8a31b09f",
   "metadata": {},
   "source": [
    "<h4 style=\"font-size:22px; font-weight:400; color:#00008B;font-family:monospace\"><u>Plotting insights:</u></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e049396c-664e-4365-bfa7-3851158af89f",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Word_Cloud:</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67f0c3-6432-4446-8c21-ec66e8b9eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=df['Message']\n",
    "text = ' '.join(words)\n",
    "# Create a WordCloud object with increased max_words\n",
    "wordcloud = WordCloud(width=1400, height=800, background_color='white', max_words=20).generate(text)\n",
    "\n",
    "# Plot the WordCloud\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa28e9be-b179-473e-b270-d97b8efd111b",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code creates a <u>WordCloud from the 'Message' column in a DataFrame</u>, <i>visualizing the most frequent words</i>. The WordCloud has a width of 1400, height of 800, and displays a maximum of 20 words. It provides a concise and visually appealing representation of the most prevalent words in the text data.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ed4ebd-1d2a-4433-b33e-8be3ca648838",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Daily_Timeline:</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac824f3-de0e-43b4-b8e9-368fde359681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "daily_timeline = df.groupby('Only_date').count()['Message'].reset_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='Only_date', y='Message', data=daily_timeline, color='maroon')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd79f8e8-f7ec-4b48-afc5-616d3249a192",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code groups a DataFrame by date, <i>counts the daily message occurrences, and creates a line plot using Seaborn</i>. The x-axis represents the dates, the y-axis shows message counts, and the maroon line depicts the daily timeline. The figure, sized 12x6, provides a clear visualization of messaging patterns over time.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7e2cc",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Monthly_Timeline::</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d2011-a0a2-4750-a517-7d25276ba6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monthly Data =====================================\n",
    "timeline = df.groupby(['Year', 'Month_No', 'Month']).count()['Message'].reset_index()\n",
    "month_timeline = []\n",
    "for i in range(timeline.shape[0]):\n",
    "  month_timeline.append(timeline['Month'][i] + \"-\" + str(timeline['Year'][i]))\n",
    "timeline['Time'] = month_timeline\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(timeline['Time'], timeline['Message'])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e041723f-40ed-4f32-8b66-b5d4db77f019",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code groups a DataFrame by year and month, <i>counting the number of messages per month</i>. It then creates a <u>timeline by combining the month and year</u>, plotting the message count over time using a line plot. The figure size is set to 12x6 for better visibility, offering a monthly message trend overview.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18498e4",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Most crowded day for the conversation:</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4791e5-9666-42f3-95d9-c5c9c6965206",
   "metadata": {},
   "outputs": [],
   "source": [
    "Busy_day = df['Day_name'].value_counts()\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(Busy_day)))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(Busy_day.index, Busy_day.values, color=colors)\n",
    "plt.title(\"Busy Day\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc4cdb-01a2-45db-b235-af347133722d",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code generates a bar plot using Matplotlib to visualize the message count for each day of the week in a DataFrame. It employs the 'viridis' colormap for varied colors, enhancing the representation of busy days. The figure size is set to 12x6 for improved visibility.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb23dd7",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li>Most active months in the conversation:</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6d79b-7b22-4648-b900-53580b7b3414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Busy Month ===========================================\n",
    "busy_month = df['Month'].value_counts()\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(busy_month)))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(busy_month.index, busy_month.values, color=colors)\n",
    "plt.title(\"Busy Month\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a6051-72c9-4a5c-a620-6179a3bef2ae",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code generates a <i>bar plot using Matplotlib to display the message count for each month in a DataFrame</i>. The 'viridis' colormap provides a range of colors, creating a visual representation of busy months. The figure has a size of 12x6 for improved readability.</font></p><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae5547",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:18px; font-weight:300; color:#00008B;font-family:monospace\">\n",
    "    <li><u>Demonstration of most active hours of each days:</u></li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e446e-e3ff-450f-b1bc-52f8ac23dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot heat_map using seaborn to show time_period each day message count\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(18, 9))\n",
    "sns.heatmap(df.pivot_table(index='Day_name', columns='Hour_Period', values='Message', \n",
    "            aggfunc='count').fillna(0))\n",
    "plt.yticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef9d8bb-7a15-4fcc-8ccd-0267af7b99ec",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The <u>seaborn heatmap</u> visualizes the count of messages for each day and time period in a DataFrame. The <i>x-axis represents different time periods, the y-axis shows days, and the color intensity corresponds to the message count</i>. The figure, with a size of 18x9, provides a clear overview of messaging patterns over days and hours.</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebc720-4c6c-4603-b78b-e4fa2137a834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#finding and creating df with dupicate wprds used in message column sorted desc\n",
    "duplicates_df = df[df.duplicated(subset='Message', keep=False)]\n",
    "duplicates_count = duplicates_df.groupby('Message').size().reset_index(name='occurrence_count')\n",
    "duplicates_count = duplicates_count.sort_values(by='occurrence_count', ascending=False)\n",
    "duplicates_count.head(50)\n",
    "#---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd47ad37-f4f2-4aec-8cdc-9f191816ecae",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">The code identifies and creates a DataFrame, `duplicates_count`, <i>containing duplicate occurrences in the 'Message' column</i> from the original DataFrame, sorted in descending order based on occurrence count. The resulting DataFrame <u>shows the top 50 duplicate messages</u> and their respective occurrence counts.</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676cee58-d464-4ba7-98ea-51f7a848425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating csv for formatted df\n",
    "try:\n",
    "    df.to_csv(r\"Chat_Formatted.csv\")\n",
    "except:\n",
    "    print(\"Failed to export\")\n",
    "finally:\n",
    "    print(\"Successfully Exported to CSV format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52523e2-1cfa-41da-a7b2-4e505a0caef3",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18;font-weight:600; color:#1E90FF;text-align:justify;text-justify: initial;font-family:monospace\">\n",
    "    <font size=\"4\">This code <i>exports the DataFrame 'df' to a CSV file named 'Chat_Formatted.csv</i>' in the 'Mini_Project' directory. The `to_csv` method is used for this, <u><i>allowing easy storage and sharing of the formatted data in a common CSV format for further analysis or reference.</i></u></font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2c7e4-76c1-46d3-9969-09de5945b514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
